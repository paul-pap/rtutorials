---
title: "Maße der zentralen Tendenz"
output:
  learnr::tutorial:
    language: de
    css: css/boxes.css
    fig_caption: no
runtime: shiny_prerendered
bibliography: ref.json
link-citations: TRUE
description: "Maße der zentralen Tendenz sowie ihre Umsetzung in R werden erklärt"
resource_files:
- css/boxes.css
---

```{r setup, include=FALSE}
library(learnr)
library(rtutorials)
library(shiny)
library(ggplot2)
if(!require(ggbrace, quietly = TRUE)){
  message("\nVersuche Paket 'ggbrace' von GitHub zu installieren. Benötigt eine Internetverbindung. \nOhne dieses Paket funktioniert eine interaktive Grafik nicht.")
  try(devtools::install_github("NicolasH2/ggbrace"))
  require(ggbrace)
}else{
    require(ggbrace)
}
require(scales)

knitr::opts_chunk$set(echo = FALSE)

iq <- c(100, 103, 114, 85, 101, 91, 84, 103, 117, 102)

```

## Inhalt

In diesem Tutorial werden die Maße der zentralen Tendenz aus der Vorlesung wiederholt sowie ihre Umsetzung in R besprochen.

## Zentrale Tendenzen

Zur Orientierung, wo wir uns im Prozess befinden: Der Datensatz ist nun erhoben und in R eingepflegt, die Analyse kann beginnen!

![](images/games.png)
<div style="text-align:left">source: https://pbs.twimg.com/media/ER24yA4XUAEGDfh.png:large</div>

<br>

Wenn du einer anderen Person jetzt von deinen Daten erzählen möchtest, könntest du natürlich jeden einzelnen Datenpunkt einzeln aufzählen. Doch seien wir ehrlich: das dauert lang und das will auch kein Mensch hören. Dann stellt sich unweigerlich die Frage: Wie kann ich in möglichst kompakter Form, am besten in einer Zahl, über meine Daten sprechen und dabei möglichst genau sein?

Die Antwort: Es kommt darauf an!

Und worauf? Ganz genau, auf das Skalenniveau. Das ist im übrigend DER Grund, warum wir uns das ganze überhaupt erst so umfassend und genau angeschaut haben!

Woher weiß ich, unabhängig von der Skala, dass ich eine gute Zahl gewählt habe, um meine Daten zu beschreiben?

Daten sind bestmöglich beschrieben, wenn die zusammenfassende Zahl den kleinstmöglichen Fehlerwert aufweist!

Das gehen wir jetzt gemeinsam Skala für Skala durch.

### Kardinalskala

```{r synonym}
question_radio("Was ist ein Synonym für Kardinalskala?,",
               answer("metrisch", 
                      correct = TRUE,
                      message = "Metrisch oder auch kardinalskaliert ist alles ab Intervallskala, das heißt, alles, wo Abstände sinnvoll interpretiert werden können."),
               answer("kategorial",
                      message = "Kategoriale Daten haben keine sinnvoll interpretierbaren Abstände, und sind deswegen nicht kardinalskaliert, auch wenn beides mit K beginnt."),
               random_answer_order = TRUE,
               allow_retry = TRUE)
```


Eben haben wir festgelegt:

> Die zusammenfassende Zahl sollte den Fehler minimieren.

Als Fehler lässt sich hier gut die summierte Abweichung von der zusammenfassenden Zahl beschreiben.
Wir möchten diese Abweichung möglichst nahe bei 0 haben.

::: aufgabe
Unten siehst du eine interaktive Grafik, die das Konzept der Abweichung von der zusammenfassenden Zahl visualisieren soll.

Nutze den Slider, um eine Zahl zu finden, wo sich die positiven und negativen Abweichungen ausbalancieren!
:::
<br>

```{r ui}
# Shiny App zum Finden des Mittelwerts

fluidPage(
  verticalLayout(
    sliderInput("zahl",
                "zusammenfassende Zahl:",
                min = 1,
                max = 10,
                value = 5,
                step = 0.5),
    mainPanel(
      plotOutput("vis", width = "100%"),
      htmlOutput("psum"),
      htmlOutput("nsum"),
      hr(),
      htmlOutput("sum"),
      br(),
      actionButton("new",
                   label = "Neue Zahlenreihe!",
                   icon = icon("rotate"))
    )
  )
)
```

```{r server, context = "server"}
# Mögliche Zahlenreihen-Längen
sizes <- 3:7

# Mögliche Zahlen: 1 - 9, ganzzahlig
sampler <- function() sample(1:9, size = sample(sizes, size = 1))

# Vektor mit allen erlaubten Mittelwerten
test_vec <- seq(from = 1, to = 9, by = 0.5)

# Zahlenreihen-Generierung
x <- reactive({
  # Nehme Abhängigkeit vom Neue Zahlenreihe Knopf
  input$new
  
  # Wiederhole Sampling, bis Mittelwert erlaubt ist
  x <- sampler()
  while(!(mean(x) %in% test_vec)){
    x <- sampler()
  }
  x |> sort()
})

  n <- reactive({
    length(x())
  })
  
df <- reactive({
    data.frame(x = x(), y = 0)
  })

# Konstruiere Basic Plot, der sich nur ändern muss wenn neue Zahlenreihe gedrückt wird. 
  p <-  reactive({
    ggplot(df(), aes(x, y)) +
      geom_point(size = 4) +
      scale_y_continuous(name = NULL, breaks = NULL) +
      theme_bw() +
      theme(text = element_text(size = 20))
  })

  diff <- reactive({
    x() - input$zahl
  })

# Positive Abweichungen
  pdiff <- reactive({
    pdiff <- diff()[diff() >= 0]
  })

# negative Abweichungen
  ndiff <- reactive({
    ndiff <- diff()[diff() < 0]
  })

# Achsenbeschriftungen 
  breaks <- reactive({
    # Kombiniere Zahlenreihe + SliderInput
    c(x(), input$zahl) |> sort() 
  })

  output$vis <- renderPlot({
    # Regeneriere Plot, wenn "neue Zahlenreihe" gedrückt wird
    input$new
    z <- input$zahl
    
    # Konstruiere Vektor h, der die Höhen der Braces enthält
    # 1. Rangfolge der negativen Abw. absteigend sortieren und * -1
    nh <- rank(ndiff()) |> sort(decreasing = T)
    nh <- nh * (-1)
    # Rangfolge der positiven Abw., startet bei 0.
    ph <- rank(pdiff()) - 1
    # Rangfolge mit dem Rang von z aus gesehen.
    ranks <- c(nh, ph)
    # Rescaling für visuelle Verhältnisse
    h <-  ranks * 0.1
    
    # Initialisiere Plot
    pl <- p()
    # Füge iterativ Braces hinzu
    for (i in 1:n()) {
      r <- ifelse(h[i] >= 0, 0, 180)
      pl <- pl +
        geom_brace(aes(x = c(z, x()[!!i]),
                       y = c(h[!!i] + 0.1, h[!!i]),
                       label = diff()[!!i]),
                   inherit.data = F,
                   rotate = r,
                   #bending = 0.05,
                   labelsize = 4,
                   textORlabel = "label",
                   labeldistance = 0.01)
    }
    # Letzte Schritte beim Plotten: Füge SliderInput hinzu
    pl + geom_vline(xintercept = z,
                   color = "#428BCA",
                   linewidth = 1.5) +
      # Füge Achsenbeschriftungen hinzu
      scale_x_continuous(name = NULL, breaks = breaks(), minor_breaks = NULL,
                         labels = scales::label_number(accuracy = 0.5))
  }) |>
    bindCache(input$zahl, input$new) # Cache den Plot-Output für mehr Schnelligkeit


  # Abweichungen insgesamt
  output$sum <- renderText({
    totalsum <- sum(diff())
    
    # Wenn Abweichungen == 0, mache den Text Grün, ansonsten schwarz
    if(totalsum == 0){
      paste0("Abweichungen insgesamt: ",
           "<font color=\"#008000\"><b>",
           round(totalsum, digits = 3),
           "</b></font>")
    } else {
       paste0("Abweichungen insgesamt: ",
           "<b>",
           round(totalsum, digits = 3),
           "</b>")
    }
  }) |> bindCache(input$zahl, input$new)

  # pos. Abw.
  output$psum <- renderText({
    paste0("Summe positiver Abweichungen:   ",
           "<b>", sum(pdiff()) |> round(digits = 3),
           "</b>")
  }) |> bindCache(input$zahl, input$new)

  # neg. Abw.
  output$nsum <- renderText({
    paste0("Summe negativer Abweichungen: ",
           "<font color=\"9c1111\"><b>",
           sum(ndiff()) |> round(digits = 3),
           "</b></font>")
  }) |> bindCache(input$zahl, input$new)
```

<br>
<br>
<hr>

Klasse! Du hast eben durch Ausprobieren diejenige Zahl gefunden, welche den wenigsten Fehler hat.  
Da es zu aufwändig wäre immer Ausprobieren zu müssen, haben sich schlaue Mathematiker*innen hingesetzt und das ganze auf Formelebene gelöst. Sie fanden heraus, dass die genaueste Zahl diejenige ist, die herauskommt, wenn du alle vorhandenen summierst und durch ihre Anzahl teilst. Also kurz: das arithmetische Mittel oder der Mittelwert, auf englisch: mean.

$$
{\large \bar{x} = \frac{\sum_{i=1}^{n}{x_i}}{n}}
$$

::: infobox
Die Funktion für den Mittelwert in R ist `mean()`.
:::
<br>

:::aufgabe
Finde den Mittelwert der Variable IQ heraus!
:::

```{r mean-solution}
mean(iq)
```

```{r mean, exercise = TRUE, exercise.cap = "Mittelwert berechnen"}
iq <- c(100, 103, 114, 85, 101, 91, 84, 103, 117, 102)

mean()
```

<br>

::: aufgabe
Nun wenden wir das auf eine Tabellenspalte an. Als Daten dient uns der Datensatz
`rtutorials::einkaufen`, welcher von Studierenden 2022 in ihrer Felderhebung erstellt wurde. Das Ziel ist, den Mittelwert der Spalte `Alter` zu berechnen.

So sieht der Datensatz aus (reduziert auf die Spalten Alter, Verkehrsmittel, Weg, Frequenz):

```{r preview, echo = FALSE}
rtutorials::einkaufen |> dplyr::select(Alter, Verkehrsmittel, Weg, Frequenz)
```

**Tipp:** Auf die Spalte `Alter` greifst du zu mittels `einkaufen$Alter`. 

Berechne den Mittelwert der Spalte `Alter`!
:::

```{r dfmean, exercise = TRUE, exercise.cap = "Mittelwert einer Tabellenspalte"}
mean()
```

```{r dfmean-solution}
mean(einkaufen$Alter)
```

Huch? Wieso kommt da `NA` raus?

`NA` heißt *Not Available* und ist in R ein spezieller Platzhalter für fehlende Werte! `NA` sagt R so etwas wie: Vorsicht, dieser Wert könnte alles enthalten. 
In Berechnungen wirkt sich `NA` sehr ansteckend aus, denn wenn ein Input alles mögliche enthalten könnte, kann auch der Output alles mögliche enthalten und ist dementsprechend auch `NA`. Daraus schließen wir, dass die Spalte `Alter` `NA`s enthält, was bei realen Daten sehr oft der Fall ist. Möglicherweise wollten einige Personen einfach nicht auf die Frage antworten, wie alt sie sind - verständlich. Dann wird `NA` eingetragen.

R zwingt uns, explizit zu sein damit, wie wir mit `NA`s umgehen. Es gibt immer eine einfache Lösung, nämlich `NA`s ausschließen und dann die Berechnung durchführen, aber wir müssen erst spezifisch sagen, dass wir das tun wollen und es passiert nicht automatisch.

Um `NA`s zu entfernen, geben wir das Argument `na.rm = TRUE` an die Funktion `mean()`!
`na.rm` steht für *NA remove*.

::: aufgabe
Verändere die Berechnung so, dass `NA`s entfernt werden!
:::

```{r narm, exercise = TRUE, exercise.cap = "NAs entfernen"}
mean(einkaufen$Alter)
```

```{r narm-solution}
mean(einkaufen$Alter, na.rm = TRUE)
```

Juhu! Es hat funktioniert!

```{r question_alter}
question_numeric("Was ist das durchschnittliche Alter im `einkaufen`-Datensatz? (Auf eine ganze Zahl gerundet)",
                 answer(43, 
                        correct = TRUE),
                 tolerance = 0.5)
```

<br>
---

Nun beweisen wir quasi rückwärts, dass das arithmetische Mittel immer der Wert ist, wo sich positive und negative Abweichungen
gegenseitig aufheben. Es gilt:

```
sum(iq - mean(iq)) == 0
```

Was dieser Code ausgesprochen bedeutet: 

1. Berechne die Differenz jedes IQ-Werts vom Mittelwert.
2. Summiere alle Differenzen
3. Prüfe, ob das Ergebnis Null ist

::: aufgabe
Wende diese Prüfung auf den Vektor `iq` an, indem du den Codeblock ausführst! Versuche die einzelnen Schritte nachzuvollziehen.
:::

```{r iq_proof, exercise = TRUE, exercise.cap = "Heben sich die Abweichungen auf?"}
# 1. Berechne Differenz jedes Werts vom Mittelwert
iq - mean(iq)

# 2. Summiere alle Differenzen
sum(iq - mean(iq))

# 3. Prüfe ob das Ergebnis Null ist

sum(iq - mean(iq)) == 0
```

<br>

::: infobox
**Take-Away**

Halten wir fest: Der Mittelwert eines kardinalskalierten Vektors ist die einfachste und genaueste Zusammenfassung all seiner einzelnen Werte!
:::

### Ordinalskala

Doch was tun, wenn du es mit ordinalskalierten Daten zu tun hast und du sie eben nicht einfach zusammenrechnen kannst (weil die Abstände nicht gleichbedeutend sind)?

Es gibt im Grunde zwei verschiedene Ansätze

  1. Du ignorierst alles, was du über Skalenniveaus gelernt hast und rechnest das arithmetische Mittel trotzdem aus. Ab 5 Faktorstufen einer ordinalskalierten Skala lässt sich mathematisch zeigen, dass du sie als metrisch betrachten und entsprechende Statistiken verwenden kannst (ganz praktisches Beispiel: Schulnoten)
  2. Du findest eine Möglichkeit die Rangplätze zu berücksichtigen.

 
\1. kannst du schon. 2. kommt jetzt:

Das gute an den rangskalierten Daten ist, dass du sie anhand ihrer Ausprägung in eine logische Reihenfolge bringen kannst:

Wir tun jetzt mal so, als wäre der IQ Vektor aus der vorherigen Aufgabe ordinalskaliert. Erinnerung: `r iq`. Als Tabelle in der richtigen Reihenfolge würde das so aussehen. (R übernimmt das mit der Funktion `sort()` oder `table()`).

| IQ Werte sortiert   | 
|:--------------------|
|84                   |
|85                   |
|91                   | 
|100                  | 
|101                  |
|102                  |
|103                  |
|103                  |
|114                  |
|117                  |

Nun werden Rangplätze vergeben. Doch: Wenn zwei Zahlen den gleichen Wert haben, werden ihre Ränge addiert und durch 2 geteilt und beiden zugewiesen. So dass in jedem Fall immer der letzte Eintrag genau den gleichen Rang hat, wie es Zahlen insgesamt gibt. (Das übernimmt R mit der Funktion `rank()`. Für die ganz Cleveren: `rank(sort())`.)

| IQ Werte sortiert   | Ränge |
|:--------------------|:------|
|84                   |1      |
|85                   |2      |
|91                   |3      |
|100                  |4      | 
|101                  |5      |
|102                  |6      |
|103                  |7.5    |
|103                  |7.5    |
|114                  |9      |
|117                  |10     |

Bei einer ungeraden Anzahl von Rängen wird der mittlere Rang genommen. Bei einer geraden Anzahl von Rängen (wie hier) werden die beiden mittleren Ränge addiert und durch 2 geteilt. Hier: $\frac{101 + 102}{2} = 101.5$. Der Median ist also 101.5. Die Funktion in R hierfür ist: `median()`

:::aufgabe
Finde mittels median() Funktion den Median für die IQ Variable raus
:::

```{r median-solution}
median(iq)
```

```{r median, exercise = T}

```

Auffällig ist, dass dieser Wert sich sehr nah am arithmethischen Mittel befindet. Es ist in manchen Fällen sinnvoll, sich beide Werte (Mittelwert und Median) anzuschauen und zu vergleichen. Wenn sie nah beieinander liegen ist es super, wenn nicht, ist es essentiell sich nochmal die Werte anzuschauen und über Außreißerwerte Gedanken zu machen und wie mit ihnen umgegangen werden soll (üblicherweise eine der drei Alternativen: rausschmeißen und Mittelwert berechnen, Ausreißer drin behalten und Mittelwert berechnen, Median berechnen)

Warum Median, wenn ich doch metrische Daten habe?

Er ist robuster und in manchen Fällen sogar (inhaltlich aussagekräftiger). ZB: Eine Person hat 0€ auf dem Konto, eine andere 100€ und die dritte eine Million. Der Mittelwert würde jetzt sagen, dass sie im Durchschnitt 333366.7 auf dem Konto haben. Das bildet die Realität nicht wirklich ab. Der Median hingegen würde 100€ sagen, was vom Verständnis her besser passt.

Eine schnelle Übersicht bietet dir die Funktion `summary()`. Hier werden dir Mittelwert (mean), Median, Reichweite (kleinster Wert und größter Wert) sowie der Interquartilsabstan (nächster Block, Tutorial Dispersionsmaße) angezeigt.

:::aufgabe
Wende die Funktion summary() auf den Vektor iq an und mach dich mit dem Ergebnis vertraut
:::

```{r summary-solution}
summary(iq)
```

```{r summary, exercise = T}

```


Zusammenfassend lässt sich also sagen: Der Median ist eine gute Zusammenfassungs für ordinalskalierte und in manchen Fällen (zB. viele/ krasse Ausreißer) auch intervallskalierte Daten.



### Nominalskala

Hier gibt es keine logische Reihenfolge. Insofern fallen Mittelwert und Median raus. Um möglichst wenige Fehler in der Vorhersage zu machen, ist es logischerweise sinnvoll, die Kategorie anzugeben, welche die meisten Werte haben. Das wird dann Modus genannt.

Gegeben sei die Lieblingsfarbe von 10 anderen Studis: `c("pink", "pink", "blau", "blau", "pink", "blau", "blau", "pink", "lila", "pink")`. Da es eine nominale Variable ist, ist es wichtig, daran zu denken, sie als `factor()` zu speichern. Um heraus zu finden, welche Gruppe am größten ist, könntest du zählen und eine Strichliste machen. ODER du lässt ganz smooth R für dich arbeiten. Hierfür brauchst du wieder die Funktion `summary()`. 

:::aufgabe
  
  1. Erstelle einen neuen Vektor namens `farben`, der ein Faktor ist und die oben angegebenen Werte enthält.
  2. Lass dir eine Zusammenfassung der Werte mit der summary Funktion ausgeben
:::

```{r nominal-solution}
farben <- factor(c("pink", "pink", "blau", "blau", "pink", "blau", "blau", "pink", "lila", "pink"))

summary(farben)
```

```{r nominal, exercise = T}

```

 
Doch warte mal - oben hat die gleiche Funktion doch auch einen ordinalen/ metrischen Vektor bearbeitet und jetzt kann sie auch nominal? Und das Ergebnis sieht auch ganz anders aus.

JA!

Deswegen war das Vektoren-Tutorial auch so wichtig! R erkennt, dass es eine andere Objektklasse ist und behandelt die Daten dementsprechend anders. Wenn du möchtest, kannst du zur Überprüfung einmal den farben Vektor ohne ihn in einen Faktor zu verwandeln in die summary Funktion stecken. Es wir ein Fehler geworfen werden - dann denkt R nämlich, dass es sich um einen Zahlenvektor handelt, und kann deswegen nichts mit den Charakter-Strings anfangen. Die Funktion `table()` kann exakt das gleiche, nur dass ihr egal ist, welche Objektklasse der Vektor hat, die funktioniert immer.

Zurück zum Modus: Das wäre in diesem Fall mit 5 Einträgen die Lieblingsfarbe Pink.

Lange Rede, kurzer Sinn: Der Modus ist die am Häufigsten vorkommende Klasse von nominalen Daten und damit die beste Möglichkeit, diese zusammen zu fassen.

## Zusammenfassung

In diesem Tutorial hast du folgende Funktionen kennengelernt:

| Funktion    | Inhalt                                              |
|:------------|:----------------------------------------------------|
| `mean()`    | Berechnet den Mittelwert.                           |
| `median()`  | Berechnet den Median.                               |
| `sort()`    | Sortiert einen Zahlenvektor.                        |
| `rank()`    | Gibt die Rangplätze eines Zahlenvektors aus.        |
| `summary()` | Gibt die zentrale Tendenz je nach Objektklasse aus. |
| `table()`   | Fasst Daten je nach Objektklasse zusammen.          |
